# OS: 메모리 관리, 가상 메모리/주소 변환, 페이지 교체, 스래싱

## 1) 메모리 관리 기본
- 프로세스는 **논리 주소 공간**을 사용하고, OS/MMU가 이를 **물리 메모리**로 매핑해 추상화한다.
- 연속 할당(세그먼트)은 단순하지만 **외부 단편화**가 생긴다. 페이징은 고정 크기 **페이지/프레임** 단위로 관리해 단편화를 줄이고 보호/공유를 쉽게 한다.
- 현대 OS는 **페이징 기반**에 지연 적재(demand paging), 메모리 매핑(mmap), Copy-on-Write로 메모리 사용을 최적화한다.
- **단편화**: 페이징은 내부 단편화(마지막 페이지 미사용 공간), 세그먼트는 외부 단편화(틈새 공간)를 가진다. 외부 단편화는 compaction(메모리 압축)으로 완화하지만 이동 비용이 크다.
- **페이지 크기 선택**: 크면 페이지 테이블이 작고 TLB 효율이 좋지만 내부 단편화와 I/O 오버헤드 증가. 작으면 단편화가 줄고 지역성을 세밀히 잡지만 TLB 미스가 늘고 페이지 테이블이 비대해진다. x86-64는 4KB 기본, 2MB/1GB huge page 지원.

## 2) 가상 메모리
- 실행에 필요한 **부분만 메모리에 적재**해 큰 주소 공간을 제공하고, 프로세스 간 격리를 보장한다.
- 장점: 메모리 효율, 더 많은 동시 실행, 보호/공유 구현 용이.
- 단점: 페이지 부재 시 디스크 I/O 지연, TLB/캐시 미스로 인한 추가 오버헤드.
- **적재 전략**: 요청 시 적재(demand paging)가 기본, 스트리밍/연속 접근 워크로드에서는 read-ahead나 애플리케이션 힌트(posix_fadvise/madvise)로 프리페치.
- **메모리 공유**: 라이브러리 코드/익명 페이지에 Copy-on-Write를 적용해 fork 후에도 필요 시점까지 쓰기 복사.

## 3) 주소 변환(MMU, 페이지 테이블, TLB)
- CPU가 가상 주소를 만들면 MMU가 **페이지 번호/오프셋**으로 분리 → TLB에서 매핑 검색 → 실패 시 페이지 테이블 조회 → 물리 프레임과 오프셋을 합쳐 물리 주소를 얻는다.
- **TLB**는 최근 매핑을 캐시한다. 미스가 잦으면 메모리 참조당 오버헤드가 커진다.
- 페이지 테이블 구조: 단일 레벨은 단순하지만 크고, **다단계/역방향** 테이블로 메모리 사용을 절감한다.
- 보호/접근 비트(읽기/쓰기/실행), 참조/dirty 비트로 보호와 교체 결정을 지원한다.
- 간단한 흐름:
  - 가상 주소 = [VPN | offset]
  - TLB hit → 물리 프레임 번호(PFN) 결합 → 물리 주소
  - TLB miss → 페이지 테이블 walk → PFN 찾기 → TLB 갱신 → 물리 주소
  - PT entry 없음 → 페이지 폴트 처리
- 주소 변환 다이어그램:
```mermaid
flowchart LR
    CPU[CPU: Virtual Address] --> MMU[MMU: VPN + offset]
    MMU --> TLB{TLB hit?}
    TLB -- hit --> PFN[PFN]
    TLB -- miss --> PTW[Page Table Walk]
    PTW --> Present{PTE present?}
    Present -- yes --> PFN
    Present -- no --> Fault[Page Fault Handler\n(load/replace page)]
    Fault --> PFN
    PFN --> PA[Physical Address = PFN + offset]
```
- **효과적 접근 시간(EAT)** 근사: `EAT = TLB_hit * 1 + (1 - TLB_hit) * PT_walk + page_fault_rate * page_fault_cost`. TLB hit 비율이 낮거나 page_fault_rate가 높으면 급격히 악화한다.
- **다단계 예시**(48bit VA, 4KB 페이지, 9-9-9-9-12 분할): 상위 36비트가 4단계 인덱스에 쓰이고, 각 테이블 엔트리는 8바이트이므로 빈 공간은 생성되지 않는다. 역방향 테이블은 물리 프레임당 1엔트리라 매우 큰 VA에도 일정 크기를 유지한다.

## 4) 페이지 부재 처리 흐름
1. 주소 변환 실패 → **페이지 폴트** 트랩 발생.
2. 빈 프레임이 있으면 사용, 없으면 **교체 알고리즘**으로 희생 프레임 선택.
3. 희생 프레임이 dirty면 디스크에 기록.
4. 필요한 페이지를 스왑 영역/파일에서 읽어 새 프레임에 적재.
5. 페이지 테이블과 TLB를 갱신하고 명령을 재시작.
- fork 이후 첫 쓰기 시 Copy-on-Write가 트랩을 일으켜 실제로 페이지를 복사하고 쓰기 가능으로 전환한다.

## 5) 페이지 교체 알고리즘
- 목표: **페이지 부재율 최소화**와 낮은 오버헤드의 균형.
- **OPT**: 미래에 가장 늦게 쓰일 페이지 제거(이론적 하한, 구현 불가).
- **FIFO**: 먼저 들어온 페이지부터 제거. 단순하지만 **Belady anomaly** 발생 가능.
- **LRU**: 가장 오래 사용하지 않은 페이지 제거. 비용이 커서 근사 기법 사용.
- **Clock/Second-Chance**: 참조 비트로 LRU를 근사, 원형 포인터로 스캔.
- **Enhanced Clock**: 참조/dirty 비트 조합으로 클린 페이지를 선호.
- **LFU/MFU**: 접근 빈도 기반. 오래된 히스토리가 남아있을 수 있어 적절한 감쇠가 필요.
| 알고리즘 | 장점 | 단점/주의 |
| --- | --- | --- |
| FIFO | 구현 간단 | Belady anomaly, 최근성 반영 못 함 |
| LRU | 직관적, 좋은 성능 | 진짜 LRU 유지 비용 큼(스택/타임스탬프) |
| Clock | LRU 근사, 낮은 오버헤드 | 참조 비트 정확도가 하드웨어 의존 |
| Enhanced Clock | dirty 고려로 I/O 비용 절감 | 구현 복잡도 증가, 스캔 길어질 수 있음 |
| LFU | 반복 참조에 강함 | 오래된 접근이 잔류, aging 필요 |
| Random | 구현 극단적 단순 | 성능 하한, 경합 낮을 때는 의외로 준수 |

## 6) 스래싱(thrashing)
- 정의: 페이지 폴트가 과도해 CPU가 대부분 I/O 대기로 낭비되는 상태.
- 원인: 프로세스 작업집합보다 적은 프레임 할당, 과도한 멀티프로그래밍, 낮은 공간 지역성.
- 대응: **작업집합/페이지 폴트 빈도(PFF)** 기반으로 프레임 재할당, 멀티프로그래밍 정도 축소, 필요 시 프리페칭이나 적재 힌트 활용, RAM 확충 검토.
- **작업집합(Working Set)**: 최근 Δ 시간/참조 창 내에 접근한 페이지 집합을 유지해 그 크기만큼 프레임을 보장하면 스래싱을 줄일 수 있다.
- **PFF(Page Fault Frequency)**: 페이지 폴트 간격을 모니터링해 너무 잦으면 프레임을 늘리고, 너무 드물면 회수한다.
- 징후: CPU 사용률 급감 + 디스크 I/O(PF/s) 급증, 런큐에 비해 처리량 저하. 프로파일링 도구(top, vmstat, perf, dtrace)로 확인한다.

## 7) 실무/튜닝 팁
- TLB/캐시 친화적으로 **순차 접근·데이터 지역성**을 높인다(배열 연속 접근, 구조체 패킹).
- 메모리 매핑 파일 사용 시 I/O 패턴을 고려하고, 필요 없는 큰 영역 매핑을 피한다.
- GC 언어는 힙 크기·GC 주기가 페이지 캐시/스왑과 상호작용하므로 런타임 옵션으로 튜닝한다.
- DB/캐시 서버처럼 페이지 캐시와 사용자 캐시가 경쟁할 때는 **워크로드에 맞는 메모리 상한**을 설정해 스래싱을 방지한다.
- **Huge page(Transparent/Explicit)**: TLB 미스를 줄이지만 내부 단편화와 메모리 압축/덤프 비용이 커진다. 대규모 연속 배열/히트맵에 선택적 사용.
- **NUMA**: 노드 로컬 할당을 유지해야 대역폭/지연을 최소화한다. 바인딩 정책(numactl)과 스레드 affinity를 맞춘다.
- **고정/핀 메모리**: 실시간/디바이스 I/O는 페이지 아웃을 막기 위해 mlock/pinned memory를 사용한다(과도 사용은 피해야 한다).
- **Overcommit 정책**: 리눅스의 `/proc/sys/vm/overcommit_memory`와 OOM Killer 동작을 이해하고, 고정 크기 서비스는 overcommit을 줄여 예측 가능성을 높인다.
